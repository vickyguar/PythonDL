{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I -  Tensorflow & Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--O_kCr-s2--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/i/lkli02223oqhlac1jetz.png\" style=\"width:800px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo I: Regla XOR en Tensorflow c/ Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]  # XOR input\n",
    "output_data = [[1, 0], [0, 1], [0, 1], [1, 0]]  # XOR output\n",
    "\n",
    "output_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "#---------------------------------------------------------------------#\n",
    "input_layer = Input(shape=2)\n",
    "dense_0 = Dense(10, activation='relu') (input_layer)\n",
    "dense_1 = Dense(10, activation='relu') (dense_0)\n",
    "dense_2 = Dense(10, activation='relu') (dense_1)\n",
    "output_layer = Dense(output_classes, activation='softmax') (dense_2)\n",
    "#---------------------------------------------------------------------#\n",
    "model = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                30        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 272\n",
      "Trainable params: 272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adam_optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=adam_optimizer, loss='binary_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.6749\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6676\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6595\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6520\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6433\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6347\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6248\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6133\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6010\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5877\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5733\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5591\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5439\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5282\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5120\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4951\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4785\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4631\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4469\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4309\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4156\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4006\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3866\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3732\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3613\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3499\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3384\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3280\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3188\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3101\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3016\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2942\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2873\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2810\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2755\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2706\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2657\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2613\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2573\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2536\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2499\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2466\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2435\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2405\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2376\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2348\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2321\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2295\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2270\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2248\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2222\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2198\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2176\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2153\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2131\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2110\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2089\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2071\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2048\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2033\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2012\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1989\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1970\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1951\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1933\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1915\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1897\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1879\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1862\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1845\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1828\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1811\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1795\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1779\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1763\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1747\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1732\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1716\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1701\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1687\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1672\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1659\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1644\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1630\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1616\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1603\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1589\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1577\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1563\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1550\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1537\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1525\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1512\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1500\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1488\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1476\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1464\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1453\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1441\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1430\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1419\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1407\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1396\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1386\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1375\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1364\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1354\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1344\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1333\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1323\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1313\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1303\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1294\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1284\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1275\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1266\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1256\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1247\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1238\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1229\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1220\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1211\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1203\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1194\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1185\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1178\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1169\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1160\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1152\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1144\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1136\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1128\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1126\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1113\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1105\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1098\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1091\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1083\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1076\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1069\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1062\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1055\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1048\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1041\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1034\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1027\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1020\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1013\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1007\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1000\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0994\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0987\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0981\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0975\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0968\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0962\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0956\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0950\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0944\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0938\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0932\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0926\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0921\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0915\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0909\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0904\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0898\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0893\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0887\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0882\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0876\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0871\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0866\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0861\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0855\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0850\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0845\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0840\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0835\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0830\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0825\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0821\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0816\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0811\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0806\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0802\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0797\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0792\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0788\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0783\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0779\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0775\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0770\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0766\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0761\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0757\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0753\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0749\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0745\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0740\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0736\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0732\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0728\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0724\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0720\n",
      "Epoch 206/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0716\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0713\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0709\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0705\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0701\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0697\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0694\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0690\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0687\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0683\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0680\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0676\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0673\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0669\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0666\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0662\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0659\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0655\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0652\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0649\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0646\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0642\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0639\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0635\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0632\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0629\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0626\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0623\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0619\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0616\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0613\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0610\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0607\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0604\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0601\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0598\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0595\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0593\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0589\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0587\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0584\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0581\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0578\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0575\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0572\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0570\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0567\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0564\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0562\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0559\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0556\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0554\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0551\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0548\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0546\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0543\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0541\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0538\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0536\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0533\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0531\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0528\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0526\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0524\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0521\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0519\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0516\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0514\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0512\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0509\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0507\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0505\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0503\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0500\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0498\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0496\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0494\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0491\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0489\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0487\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0485\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0483\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0481\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0479\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0477\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0474\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0472\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0470\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0468\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0466\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0464\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0462\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0460\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0458\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0456\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0455\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0453\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0451\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0449\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0447\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0445\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0443\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0441\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0439\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0438\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0436\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0434\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0432\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0430\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0429\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0427\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0425\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0423\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0422\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0420\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0418\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0417\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0415\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0413\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0412\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0410\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0408\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0407\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0405\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0404\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0402\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0400\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0399\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0397\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0396\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0394\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0393\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0391\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0389\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0388\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0386\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0385\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0383\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0382\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0381\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0379\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0378\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0376\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0375\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0373\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0372\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0371\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0369\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0368\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0366\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0365\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0364\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0362\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0361\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0360\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0358\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0357\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0356\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0354\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0353\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0352\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0350\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0349\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0348\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0347\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0345\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0344\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0343\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0342\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0340\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0339\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0338\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0337\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0336\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0334\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0333\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0332\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0331\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0330\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0328\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0327\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0326\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0325\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0324\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0323\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0322\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0320\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0319\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0318\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0317\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0316\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0315\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0314\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0313\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0312\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0311\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0310\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0309\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0307\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0306\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0305\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0304\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0303\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0302\n",
      "Epoch 410/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0301\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0300\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0299\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0298\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0297\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0296\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0295\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0294\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0293\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0292\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0291\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0290\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0289\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0289\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0288\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0287\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0286\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0285\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0284\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0283\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0282\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0281\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0280\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0279\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0278\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0278\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0277\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0276\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0275\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0274\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0273\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0272\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0271\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0271\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0270\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0269\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0268\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0267\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0266\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0265\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0265\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0264\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0263\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0262\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0261\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0261\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0260\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0259\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0258\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0257\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0257\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0256\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0255\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0254\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0253\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0253\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0252\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0251\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0250\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0250\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0249\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0248\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0247\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0247\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0246\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0245\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0244\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0244\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0243\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0242\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0242\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0241\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0240\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0239\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0239\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0238\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0237\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0237\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0236\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0235\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0235\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0234\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0233\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0232\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0232\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0231\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0230\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0230\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0229\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0228\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0228\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(input_data, output_data, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f93407297f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAJNCAYAAAB5m6IGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABDH0lEQVR4nO3deXydZZ3///cnJznZl2brku6llJYCLcayyVIULctYNwZ0dERFBkbUGb8i6GzO8vv+XGaQQRmRUUDHBXUUREEQkU1Z2hQKlC60lC7plq3Z15Nc3z/O6clJmqRZzp37LK/n45FH7vu675x+2hvKm+u67usy55wAAAAwvTL8LgAAACAdEcIAAAB8QAgDAADwASEMAADAB4QwAAAAHxDCAAAAfJDpdwETVV5e7hYuXOh3GQAAACe0adOmBudcxUjXki6ELVy4UDU1NX6XAQAAcEJmtne0a54OR5rZOjPbYWa7zOyWEa7fZGabI19bzKzfzEq9rAkAACAReBbCzCwg6Q5Jl0paIemDZrYi9h7n3Nedc6ucc6skfVHSU865Jq9qAgAASBRe9oStkbTLObfbOdcr6T5J68e4/4OSfuJhPQAAAAnDyzlhVZL2x5zXSjprpBvNLE/SOkk3elgPAAAYQV9fn2pra9Xd3e13KUkrJydHc+fOVVZW1rh/xssQZiO0jbZb+J9J+tNoQ5Fmdp2k6yRp/vz58akOAABIkmpra1VYWKiFCxfKbKT/fGMszjk1NjaqtrZWixYtGvfPeTkcWStpXsz5XEkHR7n3ao0xFOmcu8s5V+2cq66oGPEtTwAAMEnd3d0qKysjgE2SmamsrGzCPYlehrCNkpaa2SIzCyoctB4cfpOZFUu6UNKvPKwFAACMgQA2NZP58/MshDnnQgrP8XpU0jZJP3POvWZm15vZ9TG3vlfS75xzHV7VAgAAEldjY6NWrVqlVatWadasWaqqqoqe9/b2jvmzNTU1+sxnPjOhX2/hwoVqaGiYSslx4elirc65hyU9PKztzmHn90q618s6AABA4iorK9PmzZslSV/+8pdVUFCgz3/+89HroVBImZkjR5bq6mpVV1dPR5lxx96RAAAg4VxzzTX63Oc+p7Vr1+rmm2/Whg0bdO6552r16tU699xztWPHDknSk08+qSuuuEJSOMB9/OMf10UXXaTFixfr9ttvP+Gvc+utt2rlypVauXKlbrvtNklSR0eHLr/8cp1xxhlauXKlfvrTn0qSbrnlFq1YsUKnn376kJA4WUm3bREAAEgPr7/+un7/+98rEAiotbVVTz/9tDIzM/X73/9eX/rSl/SLX/ziuJ/Zvn27nnjiCbW1tWnZsmW64YYbRl02YtOmTbrnnnv0wgsvyDmns846SxdeeKF2796tOXPm6KGHHpIktbS0qKmpSffff7+2b98uM1Nzc/OUf3+EMAAAELXwloc8++w9X7l8QvdfeeWVCgQCksJB6KMf/ah27twpM1NfX9+IP3P55ZcrOztb2dnZqqys1JEjRzR37twR7/3jH/+o9773vcrPz5ckve9979MzzzyjdevW6fOf/7xuvvlmXXHFFTr//PMVCoWUk5Oja6+9Vpdffnm0920qGI4EAAAJ6Vg4kqR/+Id/0Nq1a7Vlyxb9+te/HnU5iOzs7OhxIBBQKBQa9fOdG3n50pNPPlmbNm3Saaedpi9+8Yv6l3/5F2VmZmrDhg16//vfrwceeEDr1q2b5O9qECEMAAAkvJaWFlVVVUmS7r333rh85gUXXKAHHnhAnZ2d6ujo0P3336/zzz9fBw8eVF5enj784Q/r85//vF588UW1t7erpaVFl112mW677bboiwRTwXAkAACImuiQ4XT5whe+oI9+9KO69dZbdfHFF8flM88880xdc801WrNmjSTp2muv1erVq/Xoo4/qpptuUkZGhrKysvTtb39bbW1tWr9+vbq7u+Wc0ze+8Y0p//o2WldcoqqurnY1NTV+lwEAQMrYtm2bli9f7ncZSW+kP0cz2+ScG3ENDYYjAQAAfEAIAwAA8AEhDAAAwAeEMAAAMOpyDRifyfz5EcIAAEhzOTk5amxsJIhNknNOjY2NysnJmdDPsURFjPaekH62cb9eP9Km9p6QvvWhM/0uCQAAz82dO1e1tbWqr6/3u5SklZOTM+rK/KMhhMXIMOlfH9oq56RAhqm7r185WQG/ywIAwFNZWVlatGiR32WkHYYjY+QFMzW/NE+S1D/gtKuu3eeKAABAqiKEDbNsZmH0+PUjbT5WAgAAUhkhbJhTZg2GsB2HCWEAAMAbhLBhTo4JYdsJYQAAwCOEsGFie8IYjgQAAF4hhA2zsCxfwUD4j+VQS7daOvt8rggAAKQiQtgwmYEMLaksiJ7voDcMAAB4gBA2giGT8wlhAADAA4SwESwb8oZkq4+VAACAVEUIG8EylqkAAAAeI4SNIHbB1h2H29jQFAAAxB0hbASzi3NUlBPeVrO1O6RDLd0+VwQAAFINIWwEZsaQJAAA8BQhbBSnzCqKHrNyPgAAiDdC2CiWDdm+iDckAQBAfBHCRrF8dkwIO0RPGAAAiC9C2ChOjnlD8o36dvWGBnysBgAApBpC2CgKc7JUVZIrSQoNOL3Z0OFzRQAAIJUQwsZwUswekrvr232sBAAApBpC2BgWV+RHj3fTEwYAAOKIEDaGJRWDPWFv1NETBgAA4ocQNoYhIYzhSAAAEEeEsDEsiR2OrO9gD0kAABA3hLAxVBRmqzA7vIdkW09I9W09PlcEAABSBSFsDGamxZWxQ5JMzgcAAPFBCDuBJeWDQ5LMCwMAAPFCCDuBJZVMzgcAAPFHCDuB4ZPzAQAA4oEQdgKLWaYCAAB4gBB2AgvK8pRh4eMDzV3q7uv3tyAAAJASCGEnkJ0Z0LzSPEmSc9KeRoYkAQDA1BHCxmFB2eC8sL2NnT5WAgAAUgUhbBwWRHrCJGkfIQwAAMQBIWwcFpQNhrC9TQxHAgCAqSOEjcO82J6wpi4fKwEAAKmCEDYOsT1h+5iYDwAA4oAQNg7zY3rCao92KdQ/4GM1AAAgFRDCxiEvmKmKwmxJUmjA6VBLt88VAQCAZEcIG6e5M3KjxweamRcGAACmhhA2TnOKB0PYoRZCGAAAmBpC2DjNLs6JHh9sZjgSAABMDSFsnGaXDPaEHWZOGAAAmCJC2DjNiekJYzgSAABMFSFsnGYxHAkAAOKIEDZOc0qYmA8AAOKHEDZO5QXZyswwSdLRzj519fb7XBEAAEhmhLBxCmSYZhYxLwwAAMQHIWwC5pQMhjDekAQAAFNBCJuA2TELth4khAEAgCkghE1A7IKth9i6CAAATAEhbAKGrJpPTxgAAJgCQtgEzGaZCgAAECeEsAkYsok3C7YCAIAp8DSEmdk6M9thZrvM7JZR7rnIzDab2Wtm9pSX9UzV7BKWqAAAAPGR6dUHm1lA0h2SLpFUK2mjmT3onNsac0+JpP+StM45t8/MKr2qJx5K84IKBjLU2z+g1u6QOnpCys/27I8QAACkMC97wtZI2uWc2+2c65V0n6T1w+75kKRfOuf2SZJzrs7DeqYsI8OG7CFJbxgAAJgsL0NYlaT9Mee1kbZYJ0uaYWZPmtkmM/tLD+uJi1kxq+Yfae3xsRIAAJDMvBxLsxHa3Ai//lskvV1SrqTnzOx559zrQz7I7DpJ10nS/PnzPSh1/CqKsqPHdW1MzgcAAJPjZU9YraR5MedzJR0c4Z5HnHMdzrkGSU9LOmP4Bznn7nLOVTvnqisqKjwreDwqCwdDWH0bPWEAAGByvAxhGyUtNbNFZhaUdLWkB4fd8ytJ55tZppnlSTpL0jYPa5qyysLB4cg6hiMBAMAkeTYc6ZwLmdmNkh6VFJB0t3PuNTO7PnL9TufcNjN7RNIrkgYkfdc5t8WrmuKhojB2OJIQBgAAJsfT9RWccw9LenhY253Dzr8u6ete1hFPlYXMCQMAAFPHivkTVFnEnDAAADB1hLAJGjInjBAGAAAmiRA2QSW5WcrMCK++0dYdUndfv88VAQCAZEQIm6CMDBs6OZ83JAEAwCQQwiZhyFph7UzOBwAAE0cIm4QK1goDAABTRAibBNYKAwAAU0UImwTWCgMAAFNFCJuE2LXCGI4EAACTQQibhNi1wurbCWEAAGDiCGGTwBIVAABgqghhk1DJxHwAADBFhLBJKC8YDGGNHT0K9Q/4WA0AAEhGhLBJCGZmqDQ/KElyTmrq6PW5IgAAkGwIYZNUUcCQJAAAmDxC2CTFLlNRTwgDAAATRAibpNh5YSxTAQAAJooQNknlBcHoMT1hAABgoghhkxS7VlgDPWEAAGCCCGGTFDsc2dDO25EAAGBiCGGTNGROGJt4AwCACSKETdLQ4Uh6wgAAwMQQwiZp6HAkc8IAAMDEEMImqTQ/qAwLHzd39qk3xNZFAABg/AhhkxTIMJXmD91DEgAAYLwIYVMQu1ZYQxvzwgAAwPgRwqYgdnJ+fTtvSAIAgPEjhE1B7Cbe9IQBAICJIIRNwdCeMOaEAQCA8SOETcHQBVsJYQAAYPwIYVNQXhgzMZ+eMAAAMAGEsCmoKMiJHtMTBgAAJoIQNgX0hAEAgMkihE3B0K2LeDsSAACMHyFsCmbkBRWI7F3U0tWnnlC/zxUBAIBkQQibgvDWRYNDko30hgEAgHEihE3RkAVbmRcGAADGiRA2RWUFTM4HAAATRwibotjJ+QxHAgCA8SKETVHsnLCmDkIYAAAYH0LYFBHCAADAZBDCpqgs9u1IQhgAABgnQtgU0RMGAAAmgxA2RbFvRzbydiQAABgnQtgUlebHvB1JTxgAABgnQtgUMRwJAAAmgxA2RUU5mcoKhPeP7OztV3cf+0cCAIATI4RNkZlpRh5vSAIAgIkhhMXBkCFJVs0HAADjQAiLgyFbF3XwhiQAADgxQlgcMDkfAABMFCEsDghhAABgoghhcRC7dVEDc8IAAMA4EMLioLQgtieMOWEAAODECGFxUMZwJAAAmCBCWBywdREAAJgoQlgcMDEfAABMFCEsDspYrBUAAEwQISwOinOzFMgI7x/Z1hNST4j9IwEAwNgIYXGQkTF0/8ijHX0+VgMAAJIBISxOYock2boIAACcCCEsTmIn5zcyLwwAAJwAISxOhi7YSggDAABjI4TFydDhSEIYAAAYGyEsToauFcacMAAAMDZCWJywdREAAJgIT0OYma0zsx1mtsvMbhnh+kVm1mJmmyNf/+hlPV4asnURE/MBAMAJZHr1wWYWkHSHpEsk1UraaGYPOue2Drv1GefcFV7VMV3YuggAAEyElz1hayTtcs7tds71SrpP0noPfz1flfF2JAAAmAAvQ1iVpP0x57WRtuHOMbOXzey3Znaqh/V4KnZOWEM7E/MBAMDYvAxhNkKbG3b+oqQFzrkzJH1T0gMjfpDZdWZWY2Y19fX18a0yTkrygrLI77i1O6S+/gF/CwIAAAnNyxBWK2lezPlcSQdjb3DOtTrn2iPHD0vKMrPy4R/knLvLOVftnKuuqKjwsOTJCxy3fyRDkgAAYHRehrCNkpaa2SIzC0q6WtKDsTeY2SyzcP+Rma2J1NPoYU2eKmXBVgAAME6evR3pnAuZ2Y2SHpUUkHS3c+41M7s+cv1OSR+QdIOZhSR1SbraOTd8yDJp8IYkAAAYL89CmBQdYnx4WNudMcffkvQtL2uYTmxdBAAAxosV8+NoyDIVvCEJAADGQAiLoyGr5tMTBgAAxkAIiyOGIwEAwHgRwuIodjiykeFIAAAwBkJYHPF2JAAAGC9CWByVFzAnDAAAjA8hLI6GLNbaTggDAACjI4TF0YyY/SNbuvrYPxIAAIyKEBZHx+0f2UlvGAAAGBkhLM4YkgQAAONBCIsz3pAEAADjQQiLs/ICFmwFAAAnRgiLs6HDkSzYCgAARkYIi7OymP0jGY4EAACjIYTFWezWRQ1MzAcAAKMghMXZ0In5DEcCAICREcLijOFIAAAwHoSwOIsdjmSdMAAAMBpCWJyV5bNEBQAAODFCWJyVsH8kAAAYB0JYnB23fyS9YQAAYASEMA8wJAkAAE6EEOYB9o8EAAAnQgjzQHnB4DIVDWxdBAAARkAI8wA9YQAA4EQIYR4Yuok3IQwAAByPEOaB8gIm5gMAgLERwjxQOmTrIuaEAQCA4xHCPMBwJAAAOBFCmAdihyOZmA8AAEZCCPNAKYu1AgCAEyCEeaAkL6gM9o8EAABjIIR5gP0jAQDAiRDCPBI7JNnA5HwAADAMIcwjZUzOBwAAYyCEeaQsZq2wRtYKAwAAwxDCPBLbE8ZaYQAAYDhCmEfKC+gJAwAAoyOEeSS2J6yhjZ4wAAAwFCHMI8wJAwAAYyGEeSR26yKWqAAAAMMRwjzCnDAAADAWQphHmBMGAADGQgjzSEF2poKZ4T/err5+dfaGfK4IAAAkEkKYR8xM5fmsFQYAAEZGCPNQWcy8sIZ25oUBAIBBhDAP8YYkAAAYDSHMQ7E9YY30hAEAgBiEMA8N2T+yg54wAAAwiBDmofKYVfPr2+gJAwAAgwhhHiovpCcMAACMjBDmoSH7RzInDAAAxCCEeWjInDDejgQAADEIYR4qZ50wAAAwCkKYh0pjVsxv6uxV/4DzsRoAAJBICGEeygpkqCQvS5LknHS0kyFJAAAQRgjzWBn7RwIAgBEQwjzG/pEAAGAkhDCPVRDCAADACAhhHmOZCgAAMBJCmMeGLNjaQU8YAAAII4R5LLYnrKGNnjAAABBGCPNY7IKt9IQBAIBjCGEeK4/tCWNOGAAAiCCEeayMnjAAADACQpjHmBMGAABGQgjzWGF2poKZ4T/mrr5+dfaGfK4IAAAkAk9DmJmtM7MdZrbLzG4Z4763mlm/mX3Ay3r8YGYqZ+siAAAwjGchzMwCku6QdKmkFZI+aGYrRrnvq5Ie9aoWv7F1EQAAGM7LnrA1knY553Y753ol3Sdp/Qj3fVrSLyTVeViLr8p4QxIAAAzjZQirkrQ/5rw20hZlZlWS3ivpTg/r8F3sqvn0hAEAAMnbEGYjtLlh57dJutk51z/mB5ldZ2Y1ZlZTX18fr/qmTUXhYAirbyOEAQAAKdPDz66VNC/mfK6kg8PuqZZ0n5lJUrmky8ws5Jx7IPYm59xdku6SpOrq6uFBLuFVxoSwurZuHysBAACJwssQtlHSUjNbJOmApKslfSj2BufcomPHZnavpN8MD2CpoLIoJoS10hMGAAA8DGHOuZCZ3ajwW48BSXc7514zs+sj11N6HlisysKc6HEdw5EAAEDe9oTJOfewpIeHtY0Yvpxz13hZi59mFjEnDAAADMWK+dNgaE9Yt5xLumltAAAgzghh0yA3GFBhdrjTsa/f6Whnn88VAQAAvxHCpklFEW9IAgCAQYSwaTJkmQrekAQAIO0RwqYJb0gCAIBYhLBpwoKtAAAgFiFsmrBgKwAAiEUImyYziwaHI1krDAAAEMKmSewm3kdaGY4EACDdEcKmCRPzAQBALELYNKkctk4Yq+YDAJDeCGHTpDA7UzlZ4T/u7r4BtfWEfK4IAAD4iRA2Tcxs6JAkb0gCAJDWCGHTiLXCAADAMYSwaRQ7L4xlKgAASG+EsGkUOxzJMhUAAKQ3Qtg0mlMyGMIONhPCAABIZ4SwaTS7ODd6fLC5y8dKAACA3whh02hOSUwIayGEAQCQzghh0yh2OPIQw5EAAKQ1Qtg0qizMUSDDJEmNHb3q7uv3uSIAAOAXQtg0CmSYZhXF9Ia10BsGAEC6IoRNs6FvSDIvDACAdEUIm2a8IQkAACRC2LQb8oYkk/MBAEhb4wphZpZvZhmR45PN7N1mluVtaampiuFIAACg8feEPS0px8yqJD0u6WOS7vWqqFQ2ZDiStcIAAEhb4w1h5pzrlPQ+Sd90zr1X0grvykpdQ4cjCWEAAKSrcYcwMztH0l9IeijSlulNSaltyIKtLd1yzvlYDQAA8Mt4Q9jfSPqipPudc6+Z2WJJT3hWVQorzs1SXjAgSers7VdLV5/PFQEAAD+MqzfLOfeUpKckKTJBv8E59xkvC0tVZqbZxTl6o75DUvgNyZK8oM9VAQCA6TbetyN/bGZFZpYvaaukHWZ2k7elpS7mhQEAgPEOR65wzrVKeo+khyXNl/QRr4pKdXN4QxIAgLQ33hCWFVkX7D2SfuWc65PEjPJJYsFWAAAw3hD2HUl7JOVLetrMFkhq9aqoVMf+kQAAYLwT82+XdHtM014zW+tNSakvtifsEMORAACkpfFOzC82s1vNrCby9R8K94phEhiOBAAA4x2OvFtSm6Q/j3y1SrrHq6JS3eziweHIw63d6h9geh0AAOlmvKveL3HOvT/m/J/NbLMH9aSFnKyAyvKDauzoVf+AU11b95A9JQEAQOobb09Yl5m97diJmZ0niclMUzCbyfkAAKS18Yaw6yXdYWZ7zGyPpG9J+ivPqkoDQ9YKY14YAABpZ7xvR74s6QwzK4qct5rZ30h6xcPaUhqr5gMAkN7G2xMmKRy+IivnS9LnPKgnbVTFhLDao4QwAADSzYRC2DAWtyrS0LzSvOjx/qOdPlYCAAD8MJUQxroKUzCvdLAnbH8TIQwAgHQz5pwwM2vTyGHLJLGmwhQM7Qnr0sCAU0YGnYsAAKSLMUOYc65wugpJN0U5WSrJy1JzZ596QwOqb+/RzKKcE/8gAABICVMZjsQUzZsR0xvGkCQAAGmFEOajIfPCmJwPAEBaIYT5KLYnbF8jy1QAAJBOCGE+WlieHz3e09jhYyUAAGC6EcJ8tCgmhO1uIIQBAJBOCGE+Whwbwurb5RxLrwEAkC4IYT6qKMxWfjAgSWrrDqmxo9fnigAAwHQhhPnIzLS4oiB6/iZDkgAApA1CmM8WDRuSBAAA6YEQ5jMm5wMAkJ4IYT5bXDEYwt6sJ4QBAJAuCGE+W1w+OCeMnjAAANIHIcxnC8sHV83f29ih/gGWqQAAIB0QwnxWmJOlysJsSVJfv9OBo2xfBABAOiCEJYDYyflvNPCGJAAA6YAQlgCYnA8AQPohhCWA2Mn5b7BWGAAAaYEQlgCWVMYu2EpPGAAA6YAQlgCWVNATBgBAuiGEJYC5M/IUDIQfRV1bj1q7+3yuCAAAeM3TEGZm68xsh5ntMrNbRri+3sxeMbPNZlZjZm/zsp5EFciwYXtIMiQJAECq8yyEmVlA0h2SLpW0QtIHzWzFsNsel3SGc26VpI9L+q5X9SS62Hlhb9QxJAkAQKrzsidsjaRdzrndzrleSfdJWh97g3Ou3Tl3bIn4fElpu1x87LywnYQwAABSnpchrErS/pjz2kjbEGb2XjPbLukhhXvD0tLSmYXR4+2HW32sBAAATAcvQ5iN0HZcT5dz7n7n3CmS3iPpX0f8ILPrInPGaurr6+NbZYI4dU5R9HjrQUIYAACpzssQVitpXsz5XEkHR7vZOfe0pCVmVj7Ctbucc9XOueqKior4V5oAFpblKzcrICn8hmR9W4/PFQEAAC95GcI2SlpqZovMLCjpakkPxt5gZieZmUWOz5QUlNToYU0JK5BhOmX24JDk1kP0hgEAkMo8C2HOuZCkGyU9KmmbpJ85514zs+vN7PrIbe+XtMXMNiv8JuVVMRP1086K2QxJAgCQLjK9/HDn3MOSHh7WdmfM8VclfdXLGpLJith5YfSEAQCQ0lgxP4GcOqc4erz1YIuPlQAAAK8RwhLIspmFyoi8U7q7oUOdvSF/CwIAAJ4hhCWQ3GBAiyOLtjonbT/c5nNFAADAK4SwBMPkfAAA0gMhLMHETs5/jXlhAACkLEJYgjm9anBy/ub9hDAAAFIVISzBnDa3WBaZnL/jcCuT8wEASFGEsARTmJOlkyKT8wec9GotvWEAAKQiQlgCWjWvJHr8cm2zb3UAAADvEMIS0Kr5JdHjjXuO+lcIAADwDCEsAZ21qCx6/MLuRvUPpO12mgAApCxCWAJaUpGvysJsSVJrd4j1wgAASEGEsARkZjpnyWBv2LNvNPhYDQAA8AIhLEGdGxPCntvd6GMlAADAC4SwBHXO4vLo8YY3m9TXP+BjNQAAIN4IYQlqXmmuqkpyJUmdvf16hfXCAABIKYSwBDV8XthzzAsDACClEMISWOy8sKd3EsIAAEglhLAEdv7Siujxpr1H1dLV52M1AAAgnghhCayiMFunzy2WJPUPOP1pF71hAACkCkJYgrtoWWX0+IntdT5WAgAA4okQluDWLhscknzy9XoNsIURAAApgRCW4E6fW6LS/KAkqb6tR1sPsYURAACpgBCW4AIZpguWDi7c+geGJAEASAmEsCSw9pTBeWGPbDnsYyUAACBeCGFJ4OJTKhXMDD+qrYdatfNIm88VAQCAqSKEJYHCnCy9Y/lgb9iDLx/0sRoAABAPhLAk8e4zqqLHv9p8UM7xliQAAMmMEJYkLlpWocKcTEnSvqZObd7f7G9BAABgSghhSSInK6B1p86Knv9qM0OSAAAkM0JYElm/anBI8tcvH1Rf/4CP1QAAgKkghCWRc5aUqbIwW5LU2NGrP7KXJAAASYsQlkQCGab1q+ZEz3+xqdbHagAAwFQQwpLM+86cGz1+9LXDqmvr9rEaAAAwWYSwJLN8dpGqF8yQJPX1O923Yb/PFQEAgMkghCWhj5yzIHr8oxf2MkEfAIAkRAhLQpeunK3ygvAE/SOtPXps6xGfKwIAABNFCEtCwcwMfWjNvOj53X9808dqAADAZBDCktSHzlqgrIBJkmr2HtWmvU0+VwQAACaCEJakZhXnDFm89c6ndvtYDQAAmChCWBL7qwsWR48f23pEu+rafKwGAABMBCEsiS2dWah3LK+Mnn+H3jAAAJIGISzJXX/hkujxA5sP6HALi7cCAJAMCGFJrnph6ZDFW7/3R3rDAABIBoSwFBDbG/bD5/epvq3Hx2oAAMB4EMJSwMWnVGr57CJJUldfv7795Bs+VwQAAE6EEJYCMjJM/+eSk6PnP3xhL3PDAABIcISwFPH25ZU6Y16JJKk3NKBvPbHT34IAAMCYCGEpwsz0uZjesJ9u3K/9TZ0+VgQAAMZCCEshFywt11sXDr4p+Z+P0xsGAECiIoSlkHBv2LLo+S9erNVL+476WBEAABgNISzFnLOkTG8/JbyKvnPSlx98TQMDzueqAADAcISwFPRPf3aqgpnhR/tybYseevWQzxUBAIDhCGEpaH5Znj523sLo+dce3a6eUL9/BQEAgOMQwlLUX190kkrysiRJ+5u69KPn9/lcEQAAiEUIS1HFuVm6ce1J0fP/fHynGtvZzggAgERBCEthHzlngeaX5kmSWrr69JXfbve5IgAAcAwhLIVlZwb05XeviJ7/fFOtavY0+VgRAAA4hhCW4i4+ZaYuWTEzev73D2xRqH/Ax4oAAIBECEsL//RnK5STFX7U2w+36QfP7fW5IgAAQAhLA3Nn5OnTFy+Nnt/62Os60trtY0UAAIAQliY+ef5iLa7IlyS194T0bw9t87kiAADSGyEsTQQzM/Sv61dGz3/98kE9uaPOx4oAAEhvhLA0ct5J5Vq/ak70/Eu/fFXNnb0+VgQAQPoihKWZf7hiRXQl/YMt3friL1/1uSIAANITISzNlBdk66vvPz16/tsth/XEdoYlAQCYboSwNPSuU2fpqup50fO/f2CL6nhbEgCAaeVpCDOzdWa2w8x2mdktI1z/CzN7JfL1rJmd4WU9GPSFdctUlJMpSTrQ3KVPfL9GfSziCgDAtPEshJlZQNIdki6VtELSB81sxbDb3pR0oXPudEn/Kukur+rBUGUF2frGVasUyDBJ0qsHWvTfz+z2uSoAANKHlz1hayTtcs7tds71SrpP0vrYG5xzzzrnjkZOn5c018N6MMzbl8/UTe9aFj3/z9/v1J6GDh8rAgAgfXgZwqok7Y85r420jeYTkn7rYT0YwbVvW6RT5xRJknpCA/rS/a/KOedzVQAApD4vQ5iN0Dbif93NbK3CIezmUa5fZ2Y1ZlZTX18fxxKRGcjQV953uiKjknr2jUb976Zaf4sCACANeBnCaiXNizmfK+ng8JvM7HRJ35W03jnXONIHOefucs5VO+eqKyoqPCk2nZ02t1ifeNui6Pm/PbRNB5u7fKwIAIDU52UI2yhpqZktMrOgpKslPRh7g5nNl/RLSR9xzr3uYS04gb+95GTNnZErSWrp6tPf3LdZId6WBADAM56FMOdcSNKNkh6VtE3Sz5xzr5nZ9WZ2feS2f5RUJum/zGyzmdV4VQ/GlhfM1K1/vio6LLlhT5O++Ydd/hYFAEAKs2SbhF1dXe1qashqXrn98Z269bFwp2SGST/+5Nk6e3GZz1UBAJCczGyTc656pGusmI8hPrX2JJ29uFSSNOCkv7lvs452sMk3AADxRgjDEIEM021XrdaMyCbfh1u7ddP/vsKyFQAAxBkhDMeZVZyjr39gcAep3287ou88zWr6AADEEyEMI3rHipn6+HmDy1Z87ZHtevaNBh8rAgAgtRDCMKpbLj1Fb1kwQ1J4fthnfvKSDrd0+1wVAACpgRCGUQUzM3THh85UeUFQktTQ3qu//tEm9YZYPwwAgKkihGFMs4pz9M0PnqlAZAGxF/c16/8+vM3nqgAASH6EMJzQOUvKdPO6ZdHze5/do5/X7B/jJwAAwIkQwjAunzx/sS5dOSt6/nf3b1HNniYfKwIAILkRwjAuZqZ/v/IMnTKrUJLU2z+g63+4SQfY6BsAgEkhhGHc8rMz9d9/Wa3S/MGJ+td+v0advSGfKwMAIPkQwjAh80rzdOeH36KsQHii/rZDrfrcT1/WwAAr6gMAMBGEMEzYmkWl+tf1K6Pnj7x2WF95ZLuPFQEAkHwIYZiUq9fM18fOWxg9v+vp3br3T2/6VxAAAEmGEIZJ+/vLV+iSFTOj5//8m616ZMthHysCACB5EMIwaYEM0+1Xr9bq+SWSJOekz973kjbtPepvYQAAJAFCGKYkNxjQ9z76Vi0qz5ck9YQGdO33N2p3fbvPlQEAkNgIYZiy0vyg7v3YW1UWWbriaGefrrlno+ra2OwbAIDREMIQFwvK8vW9a96qnKzwP1L7mjr1ke9uUHNnr8+VAQCQmAhhiJtV80p0x4cGN/vecaRNH71no9p7WMwVAIDhCGGIq7cvn6n/uPIMWTiH6eX9zbr2+xvV3dfvb2EAACQYQhji7j2rq4Ys5vr87ib99Y9eVG9owMeqAABILIQweOLDZy/QLZeeEj3/w/Y6ffonL6qvnyAGAIBECIOHrr9wiT61dkn0/NHXjujTP36JIAYAgAhh8Njn37lMnzx/UfT8kdcO6zM/IYgBAEAIg6fMTF+6bLmufdtgEPvtlsP6xPdr1MFbkwCANEYIg+fMTH93+XJ9/LzBIPb06/X6+L0b1dlLEAMApCdCGKaFmekfrliuz759abTthTeb9Il7a9TVy/IVAID0QwjDtDEz/e0lJ+uLMW9NPre7UR/53gtq6erzsTIAAKYfIQzT7q8uXKIvrFsWPa/Ze1RXfec51bWy1yQAIH0QwuCLv77oJP3jFSui59sPt+kDdz6nfY2dPlYFAMD0IYTBNx9/2yL9x5VnRPea3NfUqQ/c+ay2H271uTIAALxHCIOv3v+Wubrzw29RMDP8j2JdW4/+/M7nVLOnyefKAADwFiEMvrtkxUz94ONrVJCdKUlq7Q7pQ999Qb955aDPlQEA4B1CGBLC2YvLdN91Z6u8IChJ6g0N6MYfv6Q7n3pDzjmfqwMAIP4IYUgYK6uK9csbztPiivxo21d+u11//8AWhdjmCACQYghhSCjzy/L0yxvO1ZpFpdG2H72wT5/8QY3a2eYIAJBCCGFIOCV5Qf3PJ9bo3WfMibY9saNe7/+vZ1nCAgCQMghhSEjZmQHddtUqfWrtkmjbjiNtevcdf9SzbzT4WBkAAPFBCEPCysgw3fSuU/T1D5yuYCD8j2pzZ58+8r0N+sFze5iwDwBIaoQwJLwrq+fpJ9edrYrCbElS/4DTP/7qNX3p/lfVG2LCPgAgORHCkBTesmCGHrzxPJ0+tzja9pMN+3XVXc/pYHOXj5UBADA5hDAkjdnFufrZX52j96wanLD/0r5mXX77M3rq9XofKwMAYOIIYUgqOVkBfeOqVfq7y5ZH95w82tmna+7ZoG889rr6B5gnBgBIDoQwJB0z0ycvWKyffPJsVUbmiTkn/efjO3XNPRvU2N7jc4UAAJwYIQxJa82iUj30mfN17pKyaNszOxt0+e1/1EY2AAcAJDhCGJJaRWG2/ucTZ+nTF58UbTvc2q2rvvOcbn3sdbY7AgAkLEIYkl4gw/R/3rlM93zsrSrJy5IkDTjp9sd36srvPMcq+wCAhEQIQ8pYu6xSD3/mfJ0Vs+/kS/uaddntz+iXL9ayuCsAIKEQwpBS5pTk6sefPFtfWLdMmZG3J9t7Qvrcz17WZ+7brJauPp8rBAAgjBCGlBPIMP31RSfpFzecq0Xl+dH2X798UO/6xtN6Ykedj9UBABBGCEPKOmNeiX7z6bfpqup50bbDrd362D0bddPPX6ZXDADgK0IYUlp+dqa++oHTdeeHz1RZfjDa/vNNtXrnN57SH7Yf8bE6AEA6I4QhLaxbOVu/+9sL9GdnDG55dKS1Rx+/t0af+9lmtXTSKwYAmF6EMKSNsoJsffODq3Xnh89UecFgr9gvXzygt9/6lH61+QBvUAIApg0hDGkn3Ct2odbHbATe0N6jz963WX959wbtbezwsToAQLoghCEtleYH9Z9Xr9Z3PvIWzSzKjrY/s7NB7/zG07rjiV3qDbHaPgDAO4QwpLV3nTpLv//chbrm3IWy8LJi6gkN6OuP7tDltz+jDW+yByUAwBuEMKS9wpwsffndp+pXnzpPK6uKou0769r15995Tn/7082qa+32sUIAQCqyZJuIXF1d7WpqavwuAykq1D+g7z+3V7f+boc6evuj7fnBgN535ly978wqrZ4/w8cKAQDJxMw2OeeqR7pGTxgQIzOQoU+8bZEe+9yFuvy02dH2jt5+/c/ze/W+bz+rH7+wj7coAQBTRggDRjCnJFd3/MWZ+tG1Z+mkyoJou3PSl+5/VVff9bxe3t/sX4EAgKTHcCRwAn39A3p82xF97ZEd2t0wdPmKK06frS+86xTNL8vzqToAQCJjOBKYgqxAhtatnK0HbjxPf3nOAmVmWPTab145pLff+qT+5ddbdbSj18cqAQDJhp4wYILebOjQ1x7Zrt9uOTykvTAnUzdctETXnLtQecFMn6oDACSSsXrCCGHAJG3ae1T//8PbVLP36JD28oJs3XDREv3FWfOVkxXwqToAQCIghAEecc7pd1uP6Ku/3X7cfLFZRTn61MUn6arqeQpmMvIPAOnItzlhZrbOzHaY2S4zu2WE66eY2XNm1mNmn/eyFsALZqZ3nTpLj/7tBfq/7z1Nc4pzotcOt3brHx7YorX//qR+unGf+vrZBgkAMMiznjAzC0h6XdIlkmolbZT0Qefc1ph7KiUtkPQeSUedc/9+os+lJwyJrCfUr/s27Ne3ntil+raeIdcWlOXphguX6H1nzqVnDADShF89YWsk7XLO7XbO9Uq6T9L62Bucc3XOuY2S+jysA5g22ZkBffTchXr6prX6u8uWqzQ/GL22t7FTt/zyVV349Sd0z5/eVFfMivwAgPTjZQirkrQ/5rw20gakvNxgQJ+8YLGe+cJa3fSuZSrOzYpeO9TSrX/+9Va97at/0H89uUtt3fw/CACkIy9DmI3QNqmxTzO7zsxqzKymvr5+imUB0yc/O1OfWnuS/nTLxbrl0lNUXjDYM9bY0auvPbJD537lD/qP3+1QQ3vPGJ8EAEg1XoawWknzYs7nSjo4mQ9yzt3lnKt2zlVXVFTEpThgOhVkZ+r6C5fojzdfrH9+96lDJvC3dYf0zT/s0rlf+YNu/t9XtPNIm4+VAgCmi5chbKOkpWa2yMyCkq6W9KCHvx6Q8HKywnPGnrxprb72gdO1qDw/eq03NKCf1uzXJd94Wtfcs0F/2tXARuEAkMI8XSfMzC6TdJukgKS7nXP/n5ldL0nOuTvNbJakGklFkgYktUta4ZxrHe0zeTsSqaR/wOm3Ww7pv5/erZdrW467vnx2ka592yJdccZsZWey8CsAJBsWawUSnHNONXuP6r+f3q3Hth3R8H8ty/KDuuqt8/Shs+Zr7gw2CweAZEEIA5LInoYO3f2nN/Xzmlp19Q1dxiLDpItPmamPnLNA559UroyMkd5/AQAkCkIYkISaO3v1oxf26UfP79XBlu7jri8sy9OHz16gK98yT8V5WSN8AgDAb4QwIImF+gf0+PY6/fD5vXpmZ8Nx13OyMnTZabN1VfU8rVlUKjN6xwAgURDCgBTxRn27fvT8Pv180361dYeOu76oPF9XVs/VB86cq8qinBE+AQAwnQhhQIrp7A3pwc0H9YPn9mrroeNfJg5kmNYuq9CfV8/T2lMqlRVgr0oA8AMhDEhRzjm9eqBFP924Xw9uPqi2nuN7x8oLsvWeVXP0ntVVOnVOEcOVADCNCGFAGujq7ddvtxzSTzfu1wtvNo14z9LKAr1ndZXWr5rDUhcAMA0IYUCa2dPQoZ/V7Nf/bqpVXdvIe1KuWVSq966u0mUrZ/N2JQB4hBAGpKlQ/4D+9EajHnjpgB7Zcvi4dcckKRjI0IXLKnT5abP19uWVKswhkAFAvBDCAKijJ6THth7R/S8d0DM76zUwwr/6wcwMXbC0QlecTiADgHgghAEYoq6tW795+ZAe2HxAr4ywZ6U0GMguP32W3rF8JoEMACaBEAZgVG82dOjhVw/poVcOjbjchRQesjx/abkuWTFTb18+UxWF2dNcJQAkJ0IYgHEZTyAzk1bPK9E7VszUO1fM1JKKApa9AIBREMIATNh4ApkUXqX/khUzdcmKmTpz/gwF2FQcAKIIYQCmZG9jhx7bekSPbT2ijXuaRpzUL0kz8rJ0/tIKXXhyhS44uYJhSwBpjxAGIG6OdvTqD9vr9NjWI3p6Z706e49f9uKYlVVFuvDkCl14cqXOnF+iTLZPApBmCGEAPNHd16/n3mjU77Ye0ePbjoy6MKwkFeZk6m0nleuCkyt03pJyzSvNZS4ZgJRHCAPguYEBp22HW/XU6/V6ake9Nu09qtBo45aSqkpyde6SMp17UpnOXVKumUU501gtAEwPQhiAadfa3adndzVGQlmdDrZ0j3n/kop8nbukXOcuKdPZi8s0Iz84TZUCgHcIYQB85ZzTrrp2PfV6vf60q0Eb3mxSxxhzycykFbOLwj1lS8pVvXAGi8UCSEqEMAAJpa9/QK/UNuvZXY169o1Gbdp3VL2hgVHvzzBpZVWx3rqwVG9dWKrqhTNUXsCblwASHyEMQELr7uvXi3uP6tk3GvXsGw16ubZF/WPMJ5OkxRX5WhMJZW9dWMpEfwAJiRAGIKm094S08c0m/WlXg55/s1GvHWzVif6qmlmUHQ1kb1kwQ8tmFSqLJTEA+IwQBiCptXT2qWZvkzbsaVLNnqN6pbZZff1j/92Vk5Wh06qKtXr+DK2eV6JV80s0uzh3mioGgDBCGICU0t3Xr837m1Wzp0kb9hzVi3uPqr0ndMKfm1WUo9XzS7RqXolWz5+h06qKlRsMTEPFANIVIQxASusfcNp2qFUb9zSpZu9Rbd7XrAPNXSf8uUCGaWllgU6rKtZpc4u1sqpYK2YXKSeLYAYgPghhANJOXWu3XtrfrM37m/XSvqN6pbZlzC2WjiGYAYgnQhiAtBfqH9DOuna9tC8cyjbvb9bOuvZx/eyxYLayqlinVRXr1DlFWjarkLXLAJwQIQwARtDa3afXDrRqy4EWvXqgRVsOtGh3Q8e4f35eaa6WzyrSKbOLtHxWoZbPLtL80jxlZLBUBoAwQhgAjFNbd5+2HmyNhrJXI8FsvH9V5gUDWjarUKfMKtLy2eFgtmxWoYroNQPSEiEMAKagvSc0JJhtO9SqXXXtY25QPlxVSa6WzizQ0soCLZ1ZqKWVBTqpsoAhTSDFEcIAIM56QwPaVdeu7Ydbte1Qq7YfbtO2Q61qaO+d0OfMLs6JhrJwQCvQSZWFKs4lnAGpYKwQljndxQBAKghmZmjFnCKtmFM0pL2+rScSylq1/VCbth5q1Rv17aMuLnuopVuHWrr19Ov1Q9pnFmVraWWhTqos0JKKfC0qL9CiinzNLsphzhmQIghhABBHFYXZqiis0AUnV0TbekMD2tPYoZ1H2rWzri36/c2GjlHD2ZHWHh1p7dEfdzUMac/OzNCi8nwtrsjXovJIOCvP15KKfJXkBT39vQGIL0IYAHgsmJmhk2cW6uSZhZJmR9v7+ge0t7FTu+ra9PqRdu2sa9fOI23aXd+h3v6BET+rJzSg7YfbtP1w23HXZuRlRYPZ4op8LS7P1/yyPC0oy1dBNn/dA4mGOWEAkGBC/QPa19SpnXXt2lXXrjcbOqJfTR0Tm3N2TGl+UPNL8zS/NE8LyvI0rzRPC0rzNL8sTzMLGeIEvMKcMABIIpmBDC2uKNDiigK969Sh15o7e7W7oUNv1g8Gszfq27WnsUPdfSP3nklSU0evmjp6tXl/83HXgpkZmjcjVwvK8ocEtfmleZo7I4/9NQGPEMIAIImU5AV15vygzpw/Y0j7wIDT4dZuvdnQod317eGg1tChfU2dqm3qGnV4UwrPWXujvkNv1I+8UG1ZflBVM3JVVRL5mjH4fW5JnopyM2VGTxowUYQwAEgBGRmmOSW5mlOSq/NOKh9yrX/A6Uhrt/Y2dmp/U6f2NnVoX1OX9jWGQ9rRzr4xP7uxo1eNHb16pbZlxOsF2ZnHhbOqklzNnRE+Ls/PZrgTGAEhDABSXCAmoJ2zpOy4663dfdrX2Kl9TeGv2LB2qLn7hIvStveEtONIm3YcOf5lAUkKBjI0szhbs4tyNas4R7OLc2K+52p2cY7KC7IVIKghzRDCACDNFeVkaWVVsVZWFR937Vgv2oHmLh042qUDzV2qjXw/cLRTB5q7xpyLJkm9/QPa39Sl/U1do94TyDBVFmYPhrOi3GFhLUeVhTkKZmZM+fcLJApCGABgVLG9aG9dePx155yaOnpHCWnh7y1dYw93SuGwd2zh2pfGuK80P6jKwmxVFGarsjBHlUXZqhzhmJcJkAwIYQCASTMzlRVkq6wgW6fPLRnxno6ekA63dutwJGQdbunSoZZuHWk9dt6txnEuvXHsLc+R1kmLVZidqYrYgFaYHQlpOZEAFz7mpQL4iRAGAPBUfnamllQUaElFwaj3dPf1q661R4daunQ4JpyFz3t0uKVLdW09Gu/Slm09IbXVh7R7lDc+jwkGMlRWEFRZQVDlBdkqy89Weex5QbbK8sPHpflBhkMRV4QwAIDvcrICml8WXjx2NKH+ATV29KqutUd1bd2qa+sZetzWo/rWbtW394y6HdRwvf0D0WHQ8SjOzQoHtPzsmKAWVFlBtsrzg5FewaBK84Iqys3iZQOMiRAGAEgKmYEMzSzK0cyiHEnHv0RwjHNORzv7wuGstUf1kYB2LKzVxwS3zt7+CdXQ0tWnlq6+E/awSZKZVJKbpRn54VBWkhdUaf7g+Yy8YPg4Pyt8LS+o4twslvNII4QwAEBKMTOV5gdVmh/UKbPGvrezN6TG9l41tPeosb1XjR09ahh+3hb+3tTRqxOs1jGEc9LRzj4d7ezTbp04tElShoUX5C3JywoHtWMBLj8rGtyK87JUkpsV+R4ObjlZGcxtS0KEMABA2soLZiqvNFPzSkcfBj2mf8CpuTO8cG1DW48aOnrVGAlrDe2D4e1oZ/jlgbbu0ITrGXCDLx+MN7hJ4bltxXlZKs6NBLRISCvOjWmLhLai3CyVxFzLCjDPzS+EMAAAxiGQMfgm6MkzC094f1//gJo7+6KhrLmzV00d4fOjHb1qin7vi1ybXHCTwnPb6tvCQ68TlR8MREJbUMW5mZGglqnCnCwV5mSqKPK9MCdLRTmZKsodPC/MySTETQEhDAAAD2QFMlQRWdNsvMYKbk0d4dB2bF5aS1efmrv61NLZN+beoCfS0duvjt5+HRznywnD5WYFIqHsWEA7Ft6GBrjhge7Y/QXZmWn7AgMhDACABDGZ4OacU3ffwGAw6+yNBrTWrj41dw4LbV19aukcDHMTmec2kq6+fnX19atuEr1wxxRkZyo/O6CC7MzIcWb0uCBn6Hn4OKCC7CzlZ4cDYH6kPT+YXIGOEAYAQBIzM+UGA8oNBjSrOGdCPzsw4NTeG1JLbFDr7FNrd5/auvvU1h1SW3dIrV19au0Oqa178Htb5PtUQ5wU3n+0vSekI5p8kDsmLxhQfnamCo8Fs0hgK8gODAa64GC4W7OwVAvL86f+m5gEQhgAAGkqI8NUlJOlopwszZvEzzvn1NHbHw1lrV2R791Dvw+/HnutvWdy8+BG09nbr87e/nHPj/v3K88ghAEAgORiZtFhwtmjL902pv4Bp/aekDoivWHR4+7QsPb+Ife0d4fU0Rtz3BNSxwTXfZPCQ6F+IYQBAADfBDIsulzGVA0MOHX0htTR0z8k0LVFQ1rMcU9IbT0hzR/H8iReIYQBAICUkJFhkTcvpx7opgOLewAAAPiAEAYAAOADQhgAAIAPCGEAAAA+IIQBAAD4gBAGAADgA0IYAACADwhhAAAAPiCEAQAA+IAQBgAA4ANPQ5iZrTOzHWa2y8xuGeG6mdntkeuvmNmZXtYDAACQKDwLYWYWkHSHpEslrZD0QTNbMey2SyUtjXxdJ+nbXtUDAACQSLzsCVsjaZdzbrdzrlfSfZLWD7tnvaQfuLDnJZWY2WwPawIAAEgIXoawKkn7Y85rI20TvQcAACDleBnCbIQ2N4l7ZGbXmVmNmdXU19fHpTgAAAA/eRnCaiXNizmfK+ngJO6Rc+4u51y1c666oqIi7oUCAABMNy9D2EZJS81skZkFJV0t6cFh9zwo6S8jb0meLanFOXfIw5oAAAASQqZXH+ycC5nZjZIelRSQdLdz7jUzuz5y/U5JD0u6TNIuSZ2SPuZVPQAAAInEsxAmSc65hxUOWrFtd8YcO0mf8rIGAACARMSK+QAAAD4ghAEAAPiAEAYAAOADC0/LSh5mVi9p7zT8UuWSGqbh18H48UwSE88lMfFcEg/PJDF5/VwWOOdGXF8r6ULYdDGzGudctd91YBDPJDHxXBITzyXx8EwSk5/PheFIAAAAHxDCAAAAfEAIG91dfheA4/BMEhPPJTHxXBIPzyQx+fZcmBMGAADgA3rCAAAAfEAIG8bM1pnZDjPbZWa3+F1POjGzu82szsy2xLSVmtljZrYz8n1GzLUvRp7TDjN7lz9VpzYzm2dmT5jZNjN7zcw+G2nnufjIzHLMbIOZvRx5Lv8caee5+MzMAmb2kpn9JnLOM/GZme0xs1fNbLOZ1UTaEuK5EMJimFlA0h2SLpW0QtIHzWyFv1WllXslrRvWdoukx51zSyU9HjlX5LlcLenUyM/8V+T5Ib5Ckv6Pc265pLMlfSryZ89z8VePpIudc2dIWiVpnZmdLZ5LIvispG0x5zyTxLDWObcqZimKhHguhLCh1kja5Zzb7ZzrlXSfpPU+15Q2nHNPS2oa1rxe0vcjx9+X9J6Y9vuccz3OuTcl7VL4+SGOnHOHnHMvRo7bFP6PS5V4Lr5yYe2R06zIlxPPxVdmNlfS5ZK+G9PMM0lMCfFcCGFDVUnaH3NeG2mDf2Y65w5J4UAgqTLSzrOaZma2UNJqSS+I5+K7yLDXZkl1kh5zzvFc/HebpC9IGohp45n4z0n6nZltMrPrIm0J8VwyvfrgJGUjtPH6aGLiWU0jMyuQ9AtJf+OcazUb6Y8/fOsIbTwXDzjn+iWtMrMSSfeb2coxbue5eMzMrpBU55zbZGYXjedHRmjjmXjjPOfcQTOrlPSYmW0f495pfS70hA1VK2lezPlcSQd9qgVhR8xstiRFvtdF2nlW08TMshQOYD9yzv0y0sxzSRDOuWZJTyo8f4Xn4p/zJL3bzPYoPJXlYjP7oXgmvnPOHYx8r5N0v8LDiwnxXAhhQ22UtNTMFplZUOHJeQ/6XFO6e1DSRyPHH5X0q5j2q80s28wWSVoqaYMP9aU0C3d5fU/SNufcrTGXeC4+MrOKSA+YzCxX0jskbRfPxTfOuS865+Y65xYq/N+OPzjnPiyeia/MLN/MCo8dS3qnpC1KkOfCcGQM51zIzG6U9KikgKS7nXOv+VxW2jCzn0i6SFK5mdVK+idJX5H0MzP7hKR9kq6UJOfca2b2M0lbFX6D71OR4RnE13mSPiLp1cj8I0n6kngufpst6fuRt7YyJP3MOfcbM3tOPJdEw78r/pqp8HC9FM48P3bOPWJmG5UAz4UV8wEAAHzAcCQAAIAPCGEAAAA+IIQBAAD4gBAGAADgA0IYAACADwhhAJKemfWb2eaYr1vi+NkLzWxLvD4PAI5hnTAAqaDLObfK7yIAYCLoCQOQssxsj5l91cw2RL5OirQvMLPHzeyVyPf5kfaZZna/mb0c+To38lEBM/tvM3vNzH4XWaVeZvYZM9sa+Zz7fPptAkhShDAAqSB32HDkVTHXWp1zayR9S9JtkbZvSfqBc+50ST+SdHuk/XZJTznnzpB0pqRjO2YslXSHc+5USc2S3h9pv0XS6sjnXO/Nbw1AqmLFfABJz8zanXMFI7TvkXSxc253ZCPyw865MjNrkDTbOdcXaT/knCs3s3pJc51zPTGfsVDSY865pZHzmyVlOef+zcwekdQu6QFJDzjn2j3+rQJIIfSEAUh1bpTj0e4ZSU/Mcb8G59NeLukOSW+RtMnMmGcLYNwIYQBS3VUx35+LHD8r6erI8V9I+mPk+HFJN0iSmQXMrGi0DzWzDEnznHNPSPqCpBJJx/XGAcBo+L82AKkg18w2x5w/4pw7tkxFtpm9oPD/dH4w0vYZSXeb2U2S6iV9LNL+WUl3mdknFO7xukHSoVF+zYCkH5pZsSST9A3nXHOcfj8A0gBzwgCkrMicsGrnXIPftQDAcAxHAgAA+ICeMAAAAB/QEwYAAOADQhgAAIAPCGEAAAA+IIQBAAD4gBAGAADgA0IYAACAD/4fDJNMaSZyKYcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure(figsize=(10,10))\n",
    "plt.plot(history.history['loss'], linewidth=3, label='Train loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 121ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9784958e-01, 2.1504806e-03],\n",
       "       [7.1815474e-09, 1.0000000e+00],\n",
       "       [8.3015828e-10, 1.0000000e+00],\n",
       "       [9.9784958e-01, 2.1504806e-03]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[0., 0.], [0., 1.], [1., 0.], [1., 1.]], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo II: Regla XOR en Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense( inputs , weights, bias):\n",
    "    layer = tf.matmul(inputs, weights) + bias\n",
    "    return tf.nn.relu(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight( shape , name ):\n",
    "    return tf.Variable(tf.random.truncated_normal(shape,stddev=0.1), name=name, trainable=True, dtype=tf.float32)\n",
    "\n",
    "shapes = [[ 2 , 10 ] ,             #0\n",
    "          [ 10 , 10 ] ,            #1\n",
    "          [ 10 , 10 ] ,            #2\n",
    "          [ 10 , output_classes ]] #3\n",
    "\n",
    "weights = []\n",
    "bias = []\n",
    "for i in range( len( shapes ) ):\n",
    "    weights.append( get_weight( shapes[ i ] , 'weight{}'.format( i ) ) )\n",
    "\n",
    "for i in range( len( shapes ) ):\n",
    "    bias.append( get_weight( [1,shapes[i][-1]], 'bias{}'.format( i ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable_variables():\n",
    "    return weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'weight0:0' shape=(2, 10) dtype=float32, numpy=\n",
      "array([[ 0.03029346,  0.03671145,  0.0454985 , -0.05048889, -0.16801052,\n",
      "         0.1348326 ,  0.00184395,  0.07532348,  0.1233262 , -0.01004442],\n",
      "       [ 0.15152831, -0.03782636,  0.11472654,  0.06089356, -0.01500801,\n",
      "         0.03775572,  0.07622524, -0.07246827,  0.10007939,  0.03664825]],\n",
      "      dtype=float32)>, <tf.Variable 'weight1:0' shape=(10, 10) dtype=float32, numpy=\n",
      "array([[-0.04814712, -0.11640729, -0.12806815,  0.10223094, -0.06211672,\n",
      "         0.02357106, -0.04022299,  0.01035187, -0.13529414, -0.00967031],\n",
      "       [-0.09065782, -0.13674633, -0.14277504, -0.07212999, -0.07796696,\n",
      "        -0.09271701, -0.12326805,  0.05681676, -0.12534289, -0.09648551],\n",
      "       [ 0.1287307 , -0.01245887,  0.06160566, -0.04315779,  0.10819733,\n",
      "         0.08193904,  0.06738558,  0.16190675,  0.04568237, -0.07416682],\n",
      "       [-0.07607379, -0.03757605, -0.07458384,  0.07332394, -0.00798265,\n",
      "         0.13436101, -0.07540064,  0.04190451,  0.05847399,  0.01109455],\n",
      "       [ 0.1092507 ,  0.01185878,  0.11459347, -0.02581958,  0.03726381,\n",
      "         0.06450172, -0.04271872, -0.11113115, -0.01974518,  0.13683319],\n",
      "       [ 0.03023919, -0.03574538, -0.03686121,  0.04188276,  0.16771393,\n",
      "        -0.08012359, -0.06071067,  0.12344221,  0.03471198, -0.04857938],\n",
      "       [-0.06706473, -0.03142304,  0.07047443,  0.00066586,  0.05994835,\n",
      "        -0.03360672,  0.03337985, -0.16330974, -0.09480365, -0.04814892],\n",
      "       [ 0.03300356, -0.17821564, -0.1196601 , -0.0042296 , -0.04826434,\n",
      "         0.09274123,  0.03552083,  0.02908096, -0.04293426, -0.00038187],\n",
      "       [ 0.16475633, -0.00244643,  0.00982164, -0.06375914,  0.14481245,\n",
      "        -0.06399223, -0.03404203,  0.1473154 ,  0.07104722,  0.06378298],\n",
      "       [ 0.14788014, -0.05754724, -0.09188201,  0.06092665, -0.19016364,\n",
      "        -0.11459007,  0.08239321,  0.01886837, -0.1513743 , -0.08018816]],\n",
      "      dtype=float32)>, <tf.Variable 'weight2:0' shape=(10, 10) dtype=float32, numpy=\n",
      "array([[-0.06036351,  0.06924804,  0.08602325, -0.00533974,  0.05240151,\n",
      "        -0.05296034, -0.09364836,  0.01086691,  0.07295344,  0.14193477],\n",
      "       [-0.09179538, -0.16866522,  0.00915868, -0.05494318,  0.10840813,\n",
      "         0.03324488, -0.02145801,  0.01237288,  0.00538353,  0.13775592],\n",
      "       [ 0.062312  , -0.15522525,  0.08074241, -0.02429642, -0.05378167,\n",
      "        -0.10262453, -0.05425866,  0.04995742,  0.17164753,  0.07710502],\n",
      "       [-0.11649238, -0.05299266,  0.1485483 ,  0.11335297,  0.01215638,\n",
      "         0.07640646,  0.14704333, -0.10687839, -0.10643947, -0.07325032],\n",
      "       [-0.17363656,  0.06293022, -0.1787793 ,  0.01195719,  0.07657266,\n",
      "        -0.12389522,  0.0733204 , -0.03510986,  0.07500546, -0.10948833],\n",
      "       [ 0.08572023,  0.0624136 ,  0.0171542 , -0.14743929,  0.14884387,\n",
      "        -0.13657235, -0.11470868, -0.0149249 ,  0.07878453,  0.02415425],\n",
      "       [ 0.1161442 ,  0.11707386, -0.18108912,  0.05737702, -0.03622879,\n",
      "         0.07796125, -0.09814206, -0.04075836,  0.00801957,  0.03159639],\n",
      "       [ 0.06270361,  0.00781215, -0.05882258,  0.0258663 , -0.05870092,\n",
      "         0.06462459,  0.02904606, -0.02677262, -0.01742287,  0.07679752],\n",
      "       [ 0.09766121,  0.05010915,  0.16195282, -0.0815523 , -0.09199125,\n",
      "         0.11098468, -0.15214337, -0.13014027, -0.1791297 ,  0.05929007],\n",
      "       [ 0.09489319,  0.03541635,  0.02834003, -0.096658  ,  0.0110755 ,\n",
      "         0.11411963,  0.06424698, -0.12560868, -0.09024802,  0.01858771]],\n",
      "      dtype=float32)>, <tf.Variable 'weight3:0' shape=(10, 2) dtype=float32, numpy=\n",
      "array([[-0.05683574,  0.030928  ],\n",
      "       [ 0.01940305, -0.08637454],\n",
      "       [ 0.03744448, -0.01388181],\n",
      "       [ 0.11455984,  0.0361043 ],\n",
      "       [ 0.06727915, -0.13294339],\n",
      "       [-0.03628707, -0.01428635],\n",
      "       [ 0.09419625, -0.00239683],\n",
      "       [-0.03708687,  0.13605301],\n",
      "       [-0.0468874 ,  0.12091408],\n",
      "       [ 0.14961514,  0.02883069]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model( x ) :\n",
    "    x = tf.cast( x , dtype=tf.float32 )\n",
    "    d0 = dense(  x, weights[0], bias[0] )\n",
    "    d1 = dense( d0, weights[1], bias[1] )\n",
    "    d2 = dense( d1, weights[2], bias[2] )\n",
    "    d3 = tf.matmul(d2 , weights[3]) + bias[3]\n",
    "    return tf.nn.softmax( d3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss( pred , target ):\n",
    "    return tf.losses.binary_crossentropy( target , pred )\n",
    "\n",
    "optimizer = tf.optimizers.Adam( learning_rate )\n",
    "\n",
    "def train_step( model, inputs , outputs ):\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_loss = loss( model( inputs ), outputs)\n",
    "    grads = tape.gradient( current_loss , trainable_variables() )\n",
    "    optimizer.apply_gradients( zip( grads , trainable_variables() ) )\n",
    "    print( tf.reduce_mean( current_loss ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.6946314, shape=(), dtype=float32)\n",
      "tf.Tensor(0.693831, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6933123, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6930893, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6930677, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6931343, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69313574, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69303876, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69278777, shape=(), dtype=float32)\n",
      "tf.Tensor(0.692435, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69205415, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6918298, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6911261, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69055593, shape=(), dtype=float32)\n",
      "tf.Tensor(0.68973386, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6885491, shape=(), dtype=float32)\n",
      "tf.Tensor(0.68724144, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6855643, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6835078, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6811277, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67819405, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6746371, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6708613, shape=(), dtype=float32)\n",
      "tf.Tensor(0.66574836, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6600356, shape=(), dtype=float32)\n",
      "tf.Tensor(0.65361524, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6458981, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6370615, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6270006, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6160058, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6028731, shape=(), dtype=float32)\n",
      "tf.Tensor(0.58902895, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5737094, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5552, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5353586, shape=(), dtype=float32)\n",
      "tf.Tensor(0.51378393, shape=(), dtype=float32)\n",
      "tf.Tensor(0.49021176, shape=(), dtype=float32)\n",
      "tf.Tensor(0.46326914, shape=(), dtype=float32)\n",
      "tf.Tensor(0.43433928, shape=(), dtype=float32)\n",
      "tf.Tensor(0.40340427, shape=(), dtype=float32)\n",
      "tf.Tensor(0.37360844, shape=(), dtype=float32)\n",
      "tf.Tensor(0.34022856, shape=(), dtype=float32)\n",
      "tf.Tensor(0.30440345, shape=(), dtype=float32)\n",
      "tf.Tensor(0.26930937, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2356871, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20357022, shape=(), dtype=float32)\n",
      "tf.Tensor(0.17382951, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1459488, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12015221, shape=(), dtype=float32)\n",
      "tf.Tensor(0.098264694, shape=(), dtype=float32)\n",
      "tf.Tensor(0.078900956, shape=(), dtype=float32)\n",
      "tf.Tensor(0.062489543, shape=(), dtype=float32)\n",
      "tf.Tensor(0.04933907, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0385337, shape=(), dtype=float32)\n",
      "tf.Tensor(0.029961754, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02320386, shape=(), dtype=float32)\n",
      "tf.Tensor(0.01810019, shape=(), dtype=float32)\n",
      "tf.Tensor(0.014223339, shape=(), dtype=float32)\n",
      "tf.Tensor(0.011210224, shape=(), dtype=float32)\n",
      "tf.Tensor(0.008863712, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0070325593, shape=(), dtype=float32)\n",
      "tf.Tensor(0.005621533, shape=(), dtype=float32)\n",
      "tf.Tensor(0.004543994, shape=(), dtype=float32)\n",
      "tf.Tensor(0.003738625, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0031148319, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0026241695, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0022327597, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0019171061, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0016608179, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0014540743, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0012848243, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0011440762, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010260015, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0009274928, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00084500614, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00077456137, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0007140291, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0006617511, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0006163756, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0005768125, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0005422106, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00051171915, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00048480817, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0004614174, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0004407637, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00042232507, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00040594468, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0003915701, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00037859, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00036683283, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00035608985, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00034630124, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0003373776, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00032925923, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000321879, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00031499087, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00030864702, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00030274305, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00029720442, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002921056, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00028735722, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00028301132, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00027890404, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00027500547, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002713157, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00026781228, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00026447285, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00026128255, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002583084, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002555579, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00025285958, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002502135, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00024767173, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00024528653, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00024297589, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00024074725, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00023852606, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00023636449, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002342924, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00023230971, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00023038668, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00022850835, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00022671945, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000224938, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002232013, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00022145719, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002198174, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00021817017, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00021649315, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002148683, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00021324346, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00021171554, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00021024718, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002087416, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002072882, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00020587209, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00020450812, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002031367, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00020175785, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00020043862, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019908958, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019777035, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019648838, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019522881, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019396177, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019270966, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019145751, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019021287, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00018894585, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00018776083, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00018659067, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00018537584, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00018420572, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00018305797, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001818804, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001807252, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017959983, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017850424, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017743846, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017631309, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001752175, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017416665, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017313068, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001721022, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017106622, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017000793, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016899432, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016798073, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016696713, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001659759, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0001649847, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016403817, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016306932, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016213027, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016117633, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016020748, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001592759, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015833689, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015740532, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015650355, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015561668, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015473728, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015385044, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015296358, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015209909, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015122714, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015037754, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014953541, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014870074, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014785117, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014700904, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014617437, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014536205, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014454228, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014372253, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014295493, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014216496, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014136756, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014058508, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013982494, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013907225, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013828976, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013753708, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013676206, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013603174, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013529396, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013457854, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013383332, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013312536, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013240249, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001317169, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013098658, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013030843, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012959303, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012891486, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012820693, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012754368, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001268581, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001262023, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012555397, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012488329, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012419769, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012357172, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012290849, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012226761, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012164164, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012100076, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012037479, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00011976373, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00011915266, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001185416, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00011793799, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00011730457, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00011672332, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00011611972, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00011553847, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000114942304, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001143536, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00011377235, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000113206006, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00011263966, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00011205841, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000111506975, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00011096299, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00011036685, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00010982286, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000109308676, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00010878705, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00010822815, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00010768418, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00010713274, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000106596206, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000106096944, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00010556042, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00010504624, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00010451717, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00010401789, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00010352607, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00010304171, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00010252009, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000102020815, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001015141, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001010521, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00010055283, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000100068464, shape=(), dtype=float32)\n",
      "tf.Tensor(9.9591554e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.9137e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.864519e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.8183176e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.7713724e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.724428e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.676736e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.634262e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.586572e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.544842e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.499387e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.454676e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.409967e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.366748e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.322038e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.281799e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.2363436e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.193125e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.1528855e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.109666e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.067193e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(9.0247195e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.9844805e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.9427514e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.904003e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.861529e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.82129e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.782542e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.741558e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.703556e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.663318e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.623825e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.582841e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.546329e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.5075815e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.471069e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.432321e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.394319e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.357061e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.322039e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.283291e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.2475235e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.2132465e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.176735e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.139477e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.105201e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.0679434e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.032177e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.9979e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.964368e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.930092e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.89507e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.861538e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.826516e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.79373e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.760199e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.7259225e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.693881e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.661095e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.626819e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.596268e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.5612465e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.5299504e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.4994e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.467359e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.435318e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.4047675e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.3727264e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.3421754e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.31237e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.28182e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.249034e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.219973e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.1901675e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.161108e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.129067e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.102243e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.073927e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.044867e-05, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(7.014317e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.986001e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.957686e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.926391e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.900311e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.872741e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.8451714e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.816111e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.788541e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.760971e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.735638e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.708068e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.681988e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.6529276e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.6253575e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.600024e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.572454e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.545629e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.5210406e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.495706e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.4688815e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.4435466e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.418958e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.393624e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.368289e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.34221e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.318366e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.293777e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.268443e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.245344e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.2185194e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1954204e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1738116e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.147732e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.123143e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1000443e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.076201e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.053102e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.0307488e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(6.0061593e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.9823153e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.9592167e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.9376085e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.9174898e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.8921563e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.8705475e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.8481935e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.8258403e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.8042322e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.784114e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.7632504e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.740897e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.7192887e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.6976798e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.677562e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.6559536e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.6350902e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.614972e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.591874e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.5739907e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.5531273e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.531519e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.5121465e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.4912827e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.47191e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.4510467e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.4331642e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.4145363e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.3936732e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.3735548e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.3549273e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.333319e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.314691e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.2975538e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.2766904e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.2573174e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.240925e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.220807e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.2044146e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.1850417e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.1671588e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.148531e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.1299037e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.1105308e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.091903e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0755105e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0591178e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0397448e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0233528e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.00547e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.988333e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.9704497e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.9525668e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.934684e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.916802e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.9011545e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.882527e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.8653896e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.8512324e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.8340953e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.816957e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.8013102e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.785663e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.7685255e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.750643e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.736486e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.7200938e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.7037014e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.687309e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.6709167e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.6560148e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.640367e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.6232297e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.6083274e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.5926805e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.5770335e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.5613866e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.546484e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.5308367e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.5151897e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.501778e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.4853856e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.4727185e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.4578166e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.4414242e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.4280125e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.4116205e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.3982083e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.382561e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.3713844e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.3542474e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.3408356e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.3266788e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.3125216e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.2983647e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.2827174e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.2685602e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.2558935e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.243227e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.2268348e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.2141684e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.2000112e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.1873445e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.1746778e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.1605206e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.1463638e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.133697e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.1195402e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.1076186e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0942068e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0815405e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0666382e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.053972e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0427953e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0286388e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(4.017462e-05, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for e in range( epochs ):\n",
    "    train_step( model, input_data , output_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'weight0:0' shape=(2, 10) dtype=float32, numpy=\n",
      "array([[ 0.44084015,  0.03671145,  0.6210449 , -0.47936013, -0.16801052,\n",
      "         0.35801792,  0.34111255,  0.43057054,  0.4716355 ,  0.5296459 ],\n",
      "       [ 0.44085956, -0.03782636,  0.6660312 , -0.47934508, -0.01500801,\n",
      "         0.3580503 ,  0.41388467,  0.3951536 ,  0.47164613,  0.50736487]],\n",
      "      dtype=float32)>, <tf.Variable 'weight1:0' shape=(10, 10) dtype=float32, numpy=\n",
      "array([[ 7.35264897e-01, -1.16407290e-01, -8.66409421e-01,\n",
      "         2.18292251e-01,  6.53478622e-01,  2.35710610e-02,\n",
      "        -8.16743135e-01,  7.79636085e-01,  6.89114988e-01,\n",
      "        -9.67031159e-03],\n",
      "       [-9.06578228e-02, -1.36746332e-01, -1.42775044e-01,\n",
      "        -7.21299872e-02, -7.79669583e-02, -9.27170143e-02,\n",
      "        -1.23268045e-01,  5.68167567e-02, -1.25342891e-01,\n",
      "        -9.64855105e-02],\n",
      "       [ 3.24982256e-01, -1.24588739e-02,  5.03109634e-01,\n",
      "        -1.17575653e-01, -1.47710726e-01,  8.19390416e-02,\n",
      "         6.10716283e-01, -3.59782279e-02, -1.56874061e-01,\n",
      "        -7.41668195e-02],\n",
      "       [-2.86647767e-01, -3.75760458e-02, -5.17077208e-01,\n",
      "        -1.53106805e-02,  6.24658942e-01,  1.34361014e-01,\n",
      "        -5.50802052e-01,  7.16097414e-01,  6.69948399e-01,\n",
      "         1.10945487e-02],\n",
      "       [ 1.09250702e-01,  1.18587771e-02,  1.14593469e-01,\n",
      "        -2.58195754e-02,  3.72638106e-02,  6.45017177e-02,\n",
      "        -4.27187160e-02, -1.11131147e-01, -1.97451767e-02,\n",
      "         1.36833191e-01],\n",
      "       [ 7.64181376e-01, -3.57453786e-02, -7.49832809e-01,\n",
      "        -6.34146901e-03,  8.56455982e-01, -8.01235884e-02,\n",
      "        -7.95509934e-01,  9.35011446e-01,  8.04126441e-01,\n",
      "        -4.85793762e-02],\n",
      "       [-1.33558258e-01, -3.14230435e-02,  4.25675005e-01,\n",
      "        -6.24739043e-02,  1.30431995e-01, -3.36067155e-02,\n",
      "         5.68266273e-01,  6.25272691e-02,  2.62176408e-03,\n",
      "        -4.81489226e-02],\n",
      "       [-1.57190803e-02, -1.78215638e-01,  2.83812046e-01,\n",
      "        -1.07811160e-01, -1.31305799e-01,  9.27412286e-02,\n",
      "         6.14142299e-01, -1.17358565e-02, -1.29046604e-01,\n",
      "        -3.81865422e-04],\n",
      "       [ 9.36812520e-01, -2.44642887e-03, -7.56252825e-01,\n",
      "         3.45981121e-02,  8.47775400e-01, -6.39922321e-02,\n",
      "        -8.03855479e-01,  8.94410372e-01,  8.86521459e-01,\n",
      "         6.37829825e-02],\n",
      "       [ 3.39599550e-01, -5.75472377e-02,  3.97530019e-01,\n",
      "         8.58928397e-05, -4.96792167e-01, -1.14590071e-01,\n",
      "         6.52108729e-01, -2.16319069e-01, -4.08086717e-01,\n",
      "        -8.01881552e-02]], dtype=float32)>, <tf.Variable 'weight2:0' shape=(10, 10) dtype=float32, numpy=\n",
      "array([[-5.10552526e-01,  8.56761456e-01,  1.82575420e-01,\n",
      "         7.29453027e-01,  1.12302944e-01, -7.23311543e-01,\n",
      "        -9.36483592e-02,  1.08669121e-02, -6.41567945e-01,\n",
      "         7.64334261e-01],\n",
      "       [-9.17953774e-02, -1.68665215e-01,  9.15867649e-03,\n",
      "        -5.49431816e-02,  1.08408131e-01,  3.32448781e-02,\n",
      "        -2.14580130e-02,  1.23728840e-02,  5.38353017e-03,\n",
      "         1.37755916e-01],\n",
      "       [ 5.70767820e-01, -6.48925364e-01,  3.08297630e-02,\n",
      "        -4.67200011e-01, -1.11394048e-01,  6.91843331e-01,\n",
      "        -5.42586558e-02,  4.99574207e-02,  9.75211024e-01,\n",
      "        -3.85057598e-01],\n",
      "       [-1.16492383e-01, -1.10501729e-01,  7.16238096e-02,\n",
      "         4.54817452e-02, -4.78026904e-02,  6.12042993e-02,\n",
      "         1.47043332e-01, -1.06878392e-01, -8.48553851e-02,\n",
      "        -7.32503235e-02],\n",
      "       [-4.74783778e-01,  8.90600562e-01, -2.23657429e-01,\n",
      "         7.58915365e-01,  1.69898961e-02, -6.77332997e-01,\n",
      "         7.33203962e-02, -3.51098590e-02, -5.60972989e-01,\n",
      "         5.94665825e-01],\n",
      "       [ 8.57202262e-02,  6.24136031e-02,  1.71541963e-02,\n",
      "        -1.47439286e-01,  1.48843870e-01, -1.36572346e-01,\n",
      "        -1.14708684e-01, -1.49249015e-02,  7.87845328e-02,\n",
      "         2.41542514e-02],\n",
      "       [ 5.97492158e-01, -7.59104341e-02, -2.90909588e-01,\n",
      "        -2.17305139e-01, -9.61947888e-02,  8.85070086e-01,\n",
      "        -9.81420577e-02, -4.07583602e-02,  8.24548662e-01,\n",
      "        -2.00503320e-01],\n",
      "       [-1.94698080e-01,  8.53449702e-01, -6.00477718e-02,\n",
      "         8.07306826e-01,  3.37477453e-04, -4.11493689e-01,\n",
      "         2.90460587e-02, -2.67726183e-02, -5.56273162e-01,\n",
      "         7.79236317e-01],\n",
      "       [-2.02519104e-01,  7.33443320e-01,  6.46771789e-02,\n",
      "         5.79667807e-01, -1.51989892e-01, -3.99437547e-01,\n",
      "        -1.52143374e-01, -1.30140275e-01, -6.67562544e-01,\n",
      "         7.66200423e-01],\n",
      "       [ 9.48931947e-02,  3.54163460e-02,  2.83400323e-02,\n",
      "        -9.66579989e-02,  1.10754995e-02,  1.14119627e-01,\n",
      "         6.42469823e-02, -1.25608683e-01, -9.02480185e-02,\n",
      "         1.85877122e-02]], dtype=float32)>, <tf.Variable 'weight3:0' shape=(10, 2) dtype=float32, numpy=\n",
      "array([[-0.567119  ,  0.5412104 ],\n",
      "       [ 0.7274012 , -0.79437256],\n",
      "       [-0.0138943 ,  0.03745691],\n",
      "       [ 0.7738793 , -0.6232149 ],\n",
      "       [ 0.12483535, -0.19049954],\n",
      "       [-0.83847564,  0.78790253],\n",
      "       [ 0.09419625, -0.00239683],\n",
      "       [-0.03708687,  0.13605301],\n",
      "       [-0.7864958 ,  0.8605226 ],\n",
      "       [ 0.8358066 , -0.6573607 ]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[9.9991977e-01, 8.0252525e-05],\n",
       "       [2.7881182e-05, 9.9997211e-01],\n",
       "       [3.2558444e-05, 9.9996746e-01],\n",
       "       [9.9998009e-01, 1.9931358e-05]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
